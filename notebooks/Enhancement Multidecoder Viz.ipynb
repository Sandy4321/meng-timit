{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../models\")\n",
    "sys.path.append(\"../py_utils\")\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from ipywidgets import interact, fixed\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from models import EnhancementMultidecoder\n",
    "from kaldi_data import KaldiEvalDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# First, the env variables needed from path.sh\n",
    "os.environ[\"MODELS\"] = \"/data/sls/scratch/atitus5/meng/models\"\n",
    "os.environ[\"FEATS\"] = \"/data/sls/scratch/atitus5/meng/feats\"\n",
    "\n",
    "# Now, from models/base_config.sh\n",
    "os.environ[\"FEAT_DIM\"]=\"40\"      # 40-dim Mel filter bank\n",
    "os.environ[\"LEFT_CONTEXT\"]=\"7\"\n",
    "os.environ[\"RIGHT_CONTEXT\"]=\"7\"\n",
    "os.environ[\"OPTIMIZER\"]=\"Adam\"\n",
    "os.environ[\"LEARNING_RATE\"]=\"0.001\"\n",
    "os.environ[\"EPOCHS\"]=\"35\"\n",
    "os.environ[\"BATCH_SIZE\"]=\"128\"\n",
    "\n",
    "channels=[64,128,128]\n",
    "kernels=[5,3,3]\n",
    "downsamples=[2,0,2]\n",
    "os.environ[\"CHANNELS_DELIM\"]=\"_%s\" % (\"_\".join(map(str, channels)))\n",
    "os.environ[\"KERNELS_DELIM\"]=\"_%s\" % (\"_\".join(map(str, kernels)))\n",
    "os.environ[\"DOWNSAMPLES_DELIM\"]=\"_%s\" % (\"_\".join(map(str, downsamples)))\n",
    "\n",
    "os.environ[\"LATENT_DIM\"]=\"1024\"\n",
    "\n",
    "os.environ[\"USE_BATCH_NORM\"]=\"false\"\n",
    "\n",
    "phones_fc=[1024,1024]\n",
    "os.environ[\"PHONE_FC_DELIM\"]=\"_%s\" % (\"_\".join(map(str, phones_fc)))\n",
    "os.environ[\"NUM_PHONES\"]=\"2020\"\n",
    "\n",
    "os.environ[\"CLEAN_DATASET\"]=\"timit_clean\"\n",
    "os.environ[\"CLEAN_FEATS\"]=\"%s/%s\" % (os.environ[\"FEATS\"], os.environ[\"CLEAN_DATASET\"])\n",
    "\n",
    "os.environ[\"DIRTY_DATASET\"]=\"timit_dirty_100_rir\"\n",
    "os.environ[\"DIRTY_FEATS\"]=\"%s/%s\" % (os.environ[\"FEATS\"], os.environ[\"DIRTY_DATASET\"])\n",
    "\n",
    "os.environ[\"EXPT_NAME\"]=\"C%s_K%s_P%s_LATENT_%s_PHONE_FC_%s/BN_%s_OPT_%s_LR_%s_EPOCHS_%s_BATCH_%s\" % (os.environ[\"CHANNELS_DELIM\"],\n",
    "                                                                                                     os.environ[\"KERNELS_DELIM\"],\n",
    "                                                                                                     os.environ[\"DOWNSAMPLES_DELIM\"],\n",
    "                                                                                                     os.environ[\"LATENT_DIM\"],\n",
    "                                                                                                     os.environ[\"PHONE_FC_DELIM\"],\n",
    "                                                                                                     os.environ[\"USE_BATCH_NORM\"],\n",
    "                                                                                                     os.environ[\"OPTIMIZER\"],\n",
    "                                                                                                     os.environ[\"LEARNING_RATE\"],\n",
    "                                                                                                     os.environ[\"EPOCHS\"],\n",
    "                                                                                                     os.environ[\"BATCH_SIZE\"])\n",
    "\n",
    "os.environ[\"MODEL_DIR\"]=\"%s/%s/%s\" % (os.environ[\"MODELS\"], os.environ[\"DIRTY_DATASET\"], os.environ[\"EXPT_NAME\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using experiment C_64_128_128_K_5_3_3_P_2_0_2_LATENT_1024_PHONE_FC__1024_1024/BN_false_OPT_Adam_LR_0.001_EPOCHS_35_BATCH_128\n"
     ]
    }
   ],
   "source": [
    "# Check that the environment variables worked\n",
    "print(\"Using experiment %s\" % os.environ[\"EXPT_NAME\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set up baseline test datasets\n"
     ]
    }
   ],
   "source": [
    "clean_dataset = \"timit_clean\"\n",
    "dirty_dataset = \"timit_dirty_100_rir\"\n",
    "\n",
    "# Set up datasets for clean, dirty baselines (test set only)\n",
    "clean_feat_dir = \"%s/test\" % os.environ[\"CLEAN_FEATS\"]\n",
    "# clean_baseline = KaldiEvalDataset(os.path.join(clean_feat_dir, \"feats.scp\"))\n",
    "clean_baseline = KaldiEvalDataset(os.path.join(clean_feat_dir, \"feats-norm.scp\"))\n",
    "\n",
    "dirty_feat_dir = \"%s/test\" % os.environ[\"DIRTY_FEATS\"]\n",
    "# dirty_baseline = KaldiEvalDataset(os.path.join(dirty_feat_dir, \"feats.scp\"))\n",
    "dirty_baseline = KaldiEvalDataset(os.path.join(dirty_feat_dir, \"feats-norm.scp\"))\n",
    "\n",
    "print(\"Set up baseline test datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/data/sls/scratch/atitus5/meng/models/timit_dirty_100_rir/C_64_128_128_K_5_3_3_P_2_0_2_LATENT_1024_PHONE_FC__1024_1024/BN_false_OPT_Adam_LR_0.001_EPOCHS_35_BATCH_128/best_enhancement_md.pth.tar'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-39f62e6aef62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEnhancementMultidecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"state_dict\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/scratch/anaconda3/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module)\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/data/sls/scratch/atitus5/meng/models/timit_dirty_100_rir/C_64_128_128_K_5_3_3_P_2_0_2_LATENT_1024_PHONE_FC__1024_1024/BN_false_OPT_Adam_LR_0.001_EPOCHS_35_BATCH_128/best_enhancement_md.pth.tar'"
     ]
    }
   ],
   "source": [
    "model = EnhancementMultidecoder()\n",
    "checkpoint = torch.load(model.ckpt_path(), map_location=lambda storage,loc: storage)\n",
    "model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "freq_dim = int(os.environ[\"FEAT_DIM\"])\n",
    "left_context = int(os.environ[\"LEFT_CONTEXT\"])\n",
    "right_context = int(os.environ[\"RIGHT_CONTEXT\"])\n",
    "time_dim = (left_context + right_context + 1)\n",
    "def augmentFeats(model, feats, decoder_class):\n",
    "    feats_numpy = feats.reshape((-1, freq_dim))\n",
    "    num_frames = feats_numpy.shape[0]\n",
    "    decoded_feats = np.empty((num_frames, freq_dim))\n",
    "    for i in range(num_frames):\n",
    "        frame_spliced = np.zeros((time_dim, freq_dim))\n",
    "        frame_spliced[left_context - min(i, left_context):left_context, :] = feats_numpy[i - min(i, left_context):i, :]\n",
    "        frame_spliced[left_context, :] = feats_numpy[i, :]\n",
    "        frame_spliced[left_context + 1:left_context + 1 + min(num_frames - i - 1, right_context), :] = feats_numpy[i + 1:i + 1 + min(num_frames - i - 1, right_context), :]\n",
    "        frame_tensor = Variable(torch.FloatTensor(frame_spliced))\n",
    "\n",
    "        recon_frames = model.forward_decoder(frame_tensor, decoder_class)\n",
    "        recon_frames_numpy = recon_frames.cpu().data.numpy().reshape((-1, freq_dim))\n",
    "        decoded_feats[i, :] = recon_frames_numpy[left_context:left_context + 1, :]\n",
    "    return decoded_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0a6e4ecdb484d979ca4e7ae96af5b52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plotParallelUtts>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# color_map = \"coolwarm\"\n",
    "color_map = \"viridis\"\n",
    "def plotParallelUtts(utt_id_idx):\n",
    "    fig, axarr = plt.subplots(3, 2, sharex=True)\n",
    "    \n",
    "    fig.set_size_inches(12, 8)\n",
    "    \n",
    "    # CLEAN baseline\n",
    "    clean_baseline_utt_id = clean_baseline.utt_ids[utt_id_idx]\n",
    "    clean_baseline_feats = clean_baseline.feats_for_uttid(clean_baseline_utt_id)\n",
    "    axarr[0, 0].axis('off')    # Pretty-up the resulting output by removing gridlines\n",
    "    axarr[0, 0].imshow(np.transpose(clean_baseline_feats), origin='lower', cmap=color_map, aspect='auto', interpolation='none')\n",
    "    axarr[0, 0].set_title(\"CLEAN\")\n",
    "    \n",
    "    # DIRTY baseline\n",
    "    dirty_baseline_utt_id = dirty_baseline.utt_ids[utt_id_idx]\n",
    "    dirty_baseline_feats = dirty_baseline.feats_for_uttid(dirty_baseline_utt_id)\n",
    "    axarr[0, 1].axis('off')    # Pretty-up the resulting output by removing gridlines\n",
    "    axarr[0, 1].imshow(np.transpose(dirty_baseline_feats), origin='lower', cmap=color_map, aspect='auto', interpolation='none')\n",
    "    axarr[0, 1].set_title(\"DIRTY\")\n",
    "    \n",
    "    \n",
    "    # CLEAN->CLEAN\n",
    "    clean_clean_feats = augmentFeats(model, clean_baseline_feats, \"clean\")\n",
    "    axarr[1, 0].axis('off')    # Pretty-up the resulting output by removing gridlines\n",
    "    axarr[1, 0].imshow(np.transpose(clean_clean_feats), origin='lower', cmap=color_map, aspect='auto', interpolation='none')\n",
    "    axarr[1, 0].set_title(\"CLEAN>CLEAN\")\n",
    "    \n",
    "    # CLEAN->DIRTY\n",
    "    clean_dirty_feats = augmentFeats(model, clean_baseline_feats, \"dirty\")\n",
    "    axarr[2, 0].axis('off')    # Pretty-up the resulting output by removing gridlines\n",
    "    axarr[2, 0].imshow(np.transpose(clean_dirty_feats), origin='lower', cmap=color_map, aspect='auto', interpolation='none')\n",
    "    axarr[2, 0].set_title(\"CLEAN>DIRTY\")\n",
    "\n",
    "    \n",
    "    # DIRTY->CLEAN\n",
    "    dirty_clean_feats = augmentFeats(model, dirty_baseline_feats, \"clean\")\n",
    "    axarr[1, 1].axis('off')    # Pretty-up the resulting output by removing gridlines\n",
    "    axarr[1, 1].imshow(np.transpose(dirty_clean_feats), origin='lower', cmap=color_map, aspect='auto', interpolation='none')\n",
    "    axarr[1, 1].set_title(\"DIRTY>CLEAN\")\n",
    "    \n",
    "    # DIRTY->DIRTY\n",
    "    dirty_dirty_feats = augmentFeats(model, dirty_baseline_feats, \"dirty\")\n",
    "    axarr[2, 1].axis('off')    # Pretty-up the resulting output by removing gridlines\n",
    "    axarr[2, 1].imshow(np.transpose(dirty_dirty_feats), origin='lower', cmap=color_map, aspect='auto', interpolation='none')\n",
    "    axarr[2, 1].set_title(\"DIRTY>DIRTY\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # fig.savefig(\"%s_idx%d.eps\" % (clean_baseline_utt_id, utt_id_idx))\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "interact(plotParallelUtts, utt_id_idx=range(len(clean_baseline)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
