{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../cnn\")\n",
    "sys.path.append(\"../utils\")\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from ipywidgets import interact, fixed\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# import seaborn as sns; sns.set()\n",
    "\n",
    "from cnn_md import CNNMultidecoder, CNNVariationalMultidecoder\n",
    "from cnn_md import CNNDomainAdversarialMultidecoder\n",
    "from cnn_md import CNNGANMultidecoder\n",
    "from hao_data import HaoEvalDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise ratio 0.0\n",
      "Using experiment STRIDED_false_BACKTRANS_true_ENC_C_256_256_K_3_3_P_3_3_F_/LATENT_256/DEC_F__C_256_256_K_3_3_P_3_3/ACT_ReLU_BN_false_WEIGHT_INIT_xavier_uniform/OPT_Adam_LR_0.0001_EPOCHS_25_BATCH_128_DEBUG_false\n"
     ]
    }
   ],
   "source": [
    "# Set up environment variables for the model we want to examine\n",
    "# NOT necessarily the current environment variables!!\n",
    "\n",
    "feat_dim=80\n",
    "left_context=5\n",
    "right_context=5\n",
    "\n",
    "optimizer=\"Adam\"\n",
    "# optimizer=\"SGD\"\n",
    "learning_rate=\"0.0001\" # Use string instead of float to prevent Python's auto-formatting...\n",
    "# learning_rate=\"0.000001\" # Use string instead of float to prevent Python's auto-formatting...\n",
    "epochs=25\n",
    "# batch_size=256\n",
    "batch_size=128\n",
    "\n",
    "enc_channels=[256, 256]\n",
    "enc_kernels=[3, 3]\n",
    "enc_downsamples=[3, 3]\n",
    "enc_fc=[]\n",
    "\n",
    "latent_dim=256\n",
    "\n",
    "dec_fc=[]\n",
    "dec_channels=[256, 256]\n",
    "dec_kernels=[3, 3]\n",
    "dec_upsamples=[3, 3]\n",
    "\n",
    "decoder_classes=[\"ihm\", \"sdm1\"]\n",
    "\n",
    "use_batch_norm=False\n",
    "use_batch_norm_str = \"true\" if use_batch_norm else \"false\"\n",
    "activation=\"ReLU\"\n",
    "weight_init=\"xavier_uniform\"\n",
    "\n",
    "enc_channels_delim=\"_\" + \"_\".join(map(str, enc_channels))\n",
    "if len(enc_channels) == 0:\n",
    "     # need to recreate bash join behavior with empty array\n",
    "    enc_channels_delim=\"_\"\n",
    "enc_kernels_delim=\"_\" + \"_\".join(map(str, enc_kernels))\n",
    "if len(enc_kernels) == 0:\n",
    "     # need to recreate bash join behavior with empty array\n",
    "    enc_kernels_delim=\"_\"\n",
    "enc_downsamples_delim=\"_\" + \"_\".join(map(str, enc_downsamples))\n",
    "if len(enc_downsamples) == 0:\n",
    "     # need to recreate bash join behavior with empty array\n",
    "    enc_downsamples_delim=\"_\"\n",
    "enc_fc_delim=\"_\" + \"_\".join(map(str, enc_fc))\n",
    "if len(enc_fc) == 0:\n",
    "     # need to recreate bash join behavior with empty array\n",
    "    enc_fc_delim=\"_\"\n",
    "    \n",
    "dec_fc_delim=\"_\" + \"_\".join(map(str, dec_fc))\n",
    "if len(dec_fc) == 0:\n",
    "     # need to recreate bash join behavior with empty array\n",
    "    dec_fc_delim=\"_\"\n",
    "dec_channels_delim=\"_\" + \"_\".join(map(str, dec_channels))\n",
    "if len(dec_channels) == 0:\n",
    "     # need to recreate bash join behavior with empty array\n",
    "    dec_channels_delim=\"_\"\n",
    "dec_kernels_delim=\"_\" + \"_\".join(map(str, dec_kernels))\n",
    "if len(dec_kernels) == 0:\n",
    "     # need to recreate bash join behavior with empty array\n",
    "    dec_kernels_delim=\"_\"\n",
    "dec_upsamples_delim=\"_\" + \"_\".join(map(str, dec_upsamples))\n",
    "if len(dec_upsamples) == 0:\n",
    "     # need to recreate bash join behavior with empty array\n",
    "    dec_upsamples_delim=\"_\"\n",
    "\n",
    "debug_model = False\n",
    "debug_str = \"true\" if debug_model else \"false\"\n",
    "\n",
    "'''\n",
    "expt_name = \"ENC_C%s_K%s_P%s_F%s/LATENT_%d/DEC_F%s_C%s_K%s_P%s/ACT_%s_BN_%s_WEIGHT_INIT_%s/OPT_%s_LR_%s_EPOCHS_%d_BATCH_%d_DEBUG_%s\" % (enc_channels_delim,\n",
    "                                                                                                                                        enc_kernels_delim, \n",
    "                                                                                                                                        enc_downsamples_delim, \n",
    "                                                                                                                                        enc_fc_delim,\n",
    "                                                                                                                                        latent_dim,\n",
    "                                                                                                                                        dec_fc_delim,\n",
    "                                                                                                                                        dec_channels_delim,\n",
    "                                                                                                                                        dec_kernels_delim,                                                                                                                   dec_upsamples_delim,\n",
    "                                                                                                                                        activation,\n",
    "                                                                                                                                        use_batch_norm_str,\n",
    "                                                                                                                                        weight_init,\n",
    "                                                                                                                                        optimizer,\n",
    "                                                                                                                                        learning_rate,\n",
    "                                                                                                                                        epochs,\n",
    "                                                                                                                                        batch_size,\n",
    "                                                                                                                                        debug_str)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "use_backtranslation = True\n",
    "use_backtranslation_str = \"true\" if use_backtranslation else \"false\"\n",
    "\n",
    "strided = False\n",
    "strided_str = \"true\" if strided else \"false\"\n",
    "\n",
    "expt_name = \"STRIDED_%s_BACKTRANS_%s_ENC_C%s_K%s_P%s_F%s/LATENT_%d/DEC_F%s_C%s_K%s_P%s/ACT_%s_BN_%s_WEIGHT_INIT_%s/OPT_%s_LR_%s_EPOCHS_%d_BATCH_%d_DEBUG_%s\" % (strided_str,\n",
    "                                                                                                                                        use_backtranslation_str,\n",
    "                                                                                                                                        enc_channels_delim,\n",
    "                                                                                                                                        enc_kernels_delim, \n",
    "                                                                                                                                        enc_downsamples_delim, \n",
    "                                                                                                                                        enc_fc_delim,\n",
    "                                                                                                                                        latent_dim,\n",
    "                                                                                                                                        dec_fc_delim,\n",
    "                                                                                                                                        dec_channels_delim,\n",
    "                                                                                                                                        dec_kernels_delim,                                                                                                                   dec_upsamples_delim,\n",
    "                                                                                                                                        activation,\n",
    "                                                                                                                                        use_batch_norm_str,\n",
    "                                                                                                                                        weight_init,\n",
    "                                                                                                                                        optimizer,\n",
    "                                                                                                                                        learning_rate,\n",
    "                                                                                                                                        epochs,\n",
    "                                                                                                                                        batch_size,\n",
    "                                                                                                                                        debug_str)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "time_dim = (left_context + right_context + 1)\n",
    "freq_dim = feat_dim\n",
    "\n",
    "noise_ratio=0.0\n",
    "print(\"Noise ratio %s\" % str(noise_ratio))\n",
    "\n",
    "print(\"Using experiment %s\" % expt_name)\n",
    "\n",
    "# dataset = \"ami-0.1\"\n",
    "dataset = \"ami-full\"\n",
    "\n",
    "domain_adv_fc = [512, 512]\n",
    "domain_adv_fc_delim=\"_\" + \"_\".join(map(str, domain_adv_fc))\n",
    "if len(domain_adv_fc) == 0:\n",
    "     # need to recreate bash join behavior with empty array\n",
    "    domain_adv_fc_delim=\"_\"\n",
    "domain_adv_activation = \"LeakyReLU\"\n",
    "\n",
    "gan_fc = [512, 512]\n",
    "gan_fc_delim=\"_\" + \"_\".join(map(str, gan_fc))\n",
    "if len(gan_fc) == 0:\n",
    "     # need to recreate bash join behavior with empty array\n",
    "    gan_fc_delim=\"_\"\n",
    "gan_activation = \"LeakyReLU\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set up baseline dev datasets\n"
     ]
    }
   ],
   "source": [
    "# Set up datasets for IHM, SDM1 baselines (dev set only)\n",
    "dataset_name = \"ami-0.1\"\n",
    "current_feats = \"/data/sls/r/u/atitus5/meng/%s\" % dataset_name\n",
    "ihm_baseline = HaoEvalDataset(os.path.join(current_feats, \"ihm-dev-norm.blogmel.scp\"))\n",
    "sdm1_baseline = HaoEvalDataset(os.path.join(current_feats, \"sdm1-dev-norm.blogmel.scp\"))\n",
    "print(\"Set up baseline dev datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IF DATA AUGMENTATION NOT RUN YET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNDomainAdversarialMultidecoder(\n",
       "  (encoder_conv): Sequential(\n",
       "    (conv2d_0): Conv2d (1, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (ReLU_0): ReLU()\n",
       "    (maxpool2d_0): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), dilation=(1, 1))\n",
       "    (conv2d_1): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (ReLU_1): ReLU()\n",
       "    (maxpool2d_1): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), dilation=(1, 1))\n",
       "  )\n",
       "  (encoder_fc): Sequential(\n",
       "    (lin_final): Linear(in_features=14336, out_features=256)\n",
       "  )\n",
       "  (decoder_fc_ihm): Sequential(\n",
       "    (ReLU_final): ReLU()\n",
       "    (lin_final): Linear(in_features=256, out_features=14336)\n",
       "  )\n",
       "  (decoder_deconv_ihm): Sequential(\n",
       "    (ReLU_0): ReLU()\n",
       "    (maxunpool2d_0): MaxUnpool2d(kernel_size=(1, 3), stride=(1, 3), padding=(0, 0))\n",
       "    (conv2d_0): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
       "    (ReLU_1): ReLU()\n",
       "    (maxunpool2d_1): MaxUnpool2d(kernel_size=(1, 3), stride=(1, 3), padding=(0, 0))\n",
       "    (conv2d_1): Conv2d (256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
       "  )\n",
       "  (decoder_fc_sdm1): Sequential(\n",
       "    (ReLU_final): ReLU()\n",
       "    (lin_final): Linear(in_features=256, out_features=14336)\n",
       "  )\n",
       "  (decoder_deconv_sdm1): Sequential(\n",
       "    (ReLU_0): ReLU()\n",
       "    (maxunpool2d_0): MaxUnpool2d(kernel_size=(1, 3), stride=(1, 3), padding=(0, 0))\n",
       "    (conv2d_0): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
       "    (ReLU_1): ReLU()\n",
       "    (maxunpool2d_1): MaxUnpool2d(kernel_size=(1, 3), stride=(1, 3), padding=(0, 0))\n",
       "    (conv2d_1): Conv2d (256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
       "  )\n",
       "  (domain_adversary): Sequential(\n",
       "    (lin_0): Linear(in_features=256, out_features=512)\n",
       "    (LeakyReLU_0): LeakyReLU(0.01)\n",
       "    (lin_1): Linear(in_features=512, out_features=512)\n",
       "    (LeakyReLU_1): LeakyReLU(0.01)\n",
       "    (lin_final): Linear(in_features=512, out_features=1)\n",
       "    (LeakyReLU_final): LeakyReLU(0.01)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_type = \"ae\"\n",
    "domain_adversarial = True\n",
    "gan = False\n",
    "checkpoint_dir = \"/data/sls/scratch/atitus5/meng/models/cnn/%s/%s\" % (dataset,\n",
    "                                                                      expt_name)\n",
    "\n",
    "if domain_adversarial:\n",
    "    checkpoint_file = \"%s/best_cnn_domain_adversarial_fc_%s_act_%s_%s_ratio%s_md.pth.tar\" % (checkpoint_dir,\n",
    "                                                                      domain_adv_fc_delim,\n",
    "                                                                      domain_adv_activation,\n",
    "                                                                      model_type,\n",
    "                                                                      str(noise_ratio))\n",
    "    \n",
    "    if model_type == \"ae\":\n",
    "        model = CNNDomainAdversarialMultidecoder(freq_dim=freq_dim,\n",
    "                                splicing=[left_context, right_context], \n",
    "                                enc_channel_sizes=enc_channels,\n",
    "                                enc_kernel_sizes=enc_kernels,\n",
    "                                enc_downsample_sizes=enc_downsamples,\n",
    "                                enc_fc_sizes=enc_fc,\n",
    "                                latent_dim=latent_dim,\n",
    "                                dec_fc_sizes=dec_fc,\n",
    "                                dec_channel_sizes=dec_channels,\n",
    "                                dec_kernel_sizes=dec_kernels,\n",
    "                                dec_upsample_sizes=dec_upsamples,\n",
    "                                activation=activation,\n",
    "                                decoder_classes=decoder_classes,\n",
    "                                use_batch_norm=use_batch_norm,\n",
    "                                weight_init=weight_init,\n",
    "                                domain_adv_fc_sizes=domain_adv_fc,\n",
    "                                domain_adv_activation=domain_adv_activation)\n",
    "    elif model_type == \"vae\":\n",
    "        print(\"Adversarial VAE not supported yet\")\n",
    "elif gan:\n",
    "    checkpoint_file = \"%s/best_cnn_gan_fc_%s_act_%s_%s_ratio%s_md.pth.tar\" % (checkpoint_dir,\n",
    "                                                                      gan_fc_delim,\n",
    "                                                                      gan_activation,\n",
    "                                                                      model_type,\n",
    "                                                                      str(noise_ratio))\n",
    "    \n",
    "    if model_type == \"ae\":\n",
    "        model = CNNGANMultidecoder(freq_dim=freq_dim,\n",
    "                                splicing=[left_context, right_context], \n",
    "                                enc_channel_sizes=enc_channels,\n",
    "                                enc_kernel_sizes=enc_kernels,\n",
    "                                enc_downsample_sizes=enc_downsamples,\n",
    "                                enc_fc_sizes=enc_fc,\n",
    "                                latent_dim=latent_dim,\n",
    "                                dec_fc_sizes=dec_fc,\n",
    "                                dec_channel_sizes=dec_channels,\n",
    "                                dec_kernel_sizes=dec_kernels,\n",
    "                                dec_upsample_sizes=dec_upsamples,\n",
    "                                activation=activation,\n",
    "                                decoder_classes=decoder_classes,\n",
    "                                use_batch_norm=use_batch_norm,\n",
    "                                weight_init=weight_init,\n",
    "                                gan_fc_sizes=gan_fc,\n",
    "                                gan_activation=gan_activation)\n",
    "    elif model_type == \"vae\":\n",
    "        print(\"Generative adversarial VAE not supported yet\")\n",
    "else:\n",
    "    checkpoint_file = \"%s/best_cnn_%s_ratio%s_md.pth.tar\" % (checkpoint_dir,\n",
    "                                                             model_type,\n",
    "                                                             str(noise_ratio))\n",
    "    \n",
    "    if model_type == \"ae\":\n",
    "        model = CNNMultidecoder(freq_dim=freq_dim,\n",
    "                                splicing=[left_context, right_context], \n",
    "                                enc_channel_sizes=enc_channels,\n",
    "                                enc_kernel_sizes=enc_kernels,\n",
    "                                enc_downsample_sizes=enc_downsamples,\n",
    "                                enc_fc_sizes=enc_fc,\n",
    "                                latent_dim=latent_dim,\n",
    "                                dec_fc_sizes=dec_fc,\n",
    "                                dec_channel_sizes=dec_channels,\n",
    "                                dec_kernel_sizes=dec_kernels,\n",
    "                                dec_upsample_sizes=dec_upsamples,\n",
    "                                activation=activation,\n",
    "                                decoder_classes=decoder_classes,\n",
    "                                use_batch_norm=use_batch_norm,\n",
    "                                weight_init=weight_init)\n",
    "    elif model_type == \"vae\":\n",
    "        model = CNNVariationalMultidecoder(freq_dim=freq_dim,\n",
    "                                splicing=[left_context, right_context], \n",
    "                                enc_channel_sizes=enc_channels,\n",
    "                                enc_kernel_sizes=enc_kernels,\n",
    "                                enc_downsample_sizes=enc_downsamples,\n",
    "                                enc_fc_sizes=enc_fc,\n",
    "                                latent_dim=latent_dim,\n",
    "                                dec_fc_sizes=dec_fc,\n",
    "                                dec_channel_sizes=dec_channels,\n",
    "                                dec_kernel_sizes=dec_kernels,\n",
    "                                dec_upsample_sizes=dec_upsamples,\n",
    "                                activation=activation,\n",
    "                                decoder_classes=decoder_classes,\n",
    "                                use_batch_norm=use_batch_norm,\n",
    "                                weight_init=weight_init)\n",
    "        \n",
    "        \n",
    "checkpoint = torch.load(checkpoint_file, map_location=lambda storage,loc: storage)\n",
    "model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def augmentFeats(model, feats, decoder_class):\n",
    "    feats_numpy = feats.reshape((-1, freq_dim))\n",
    "    num_frames = feats_numpy.shape[0]\n",
    "    decoded_feats = np.empty((num_frames, freq_dim))\n",
    "    for i in range(num_frames):\n",
    "        frame_spliced = np.zeros((time_dim, freq_dim))\n",
    "        frame_spliced[left_context - min(i, left_context):left_context, :] = feats_numpy[i - min(i, left_context):i, :]\n",
    "        frame_spliced[left_context, :] = feats_numpy[i, :]\n",
    "        frame_spliced[left_context + 1:left_context + 1 + min(num_frames - i - 1, right_context), :] = feats_numpy[i + 1:i + 1 + min(num_frames - i - 1, right_context), :]\n",
    "        frame_tensor = Variable(torch.FloatTensor(frame_spliced))\n",
    "\n",
    "        if model_type == \"ae\":\n",
    "            recon_frames = model.forward_decoder(frame_tensor, decoder_class)\n",
    "        elif model_type == \"vae\":\n",
    "            recon_frames, mu, logvar = model.forward_decoder(frame_tensor, decoder_class)\n",
    "        else:\n",
    "            print(\"Unrecognized model type %s\" % model_type)\n",
    "        recon_frames_numpy = recon_frames.cpu().data.numpy().reshape((-1, freq_dim))\n",
    "        decoded_feats[i, :] = recon_frames_numpy[left_context:left_context + 1, :]\n",
    "    return decoded_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "962f144b14ca4e1d9f8ade51698970ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plotParallelUtts>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# color_map = \"coolwarm\"\n",
    "color_map = \"viridis\"\n",
    "def plotParallelUtts(utt_id_idx):\n",
    "    fig, axarr = plt.subplots(10, sharex=True)\n",
    "    \n",
    "    fig.set_size_inches(8.5, 22)\n",
    "    \n",
    "    # IHM baseline\n",
    "    ihm_baseline_utt_id = ihm_baseline.utt_ids[utt_id_idx]\n",
    "    ihm_baseline_feats = ihm_baseline.feats_for_uttid(ihm_baseline_utt_id)\n",
    "    axarr[0].axis('off')    # Pretty-up the resulting output by removing gridlines\n",
    "    axarr[0].imshow(np.transpose(ihm_baseline_feats), origin='lower', cmap=color_map, aspect='auto', interpolation='none')\n",
    "    axarr[0].set_title(\"IHM\")\n",
    "    \n",
    "    # SDM1 baseline\n",
    "    sdm1_baseline_utt_id = sdm1_baseline.utt_ids[utt_id_idx]\n",
    "    sdm1_baseline_feats = sdm1_baseline.feats_for_uttid(sdm1_baseline_utt_id)\n",
    "    axarr[1].axis('off')    # Pretty-up the resulting output by removing gridlines\n",
    "    axarr[1].imshow(np.transpose(sdm1_baseline_feats), origin='lower', cmap=color_map, aspect='auto', interpolation='none')\n",
    "    axarr[1].set_title(\"SDM1\")\n",
    "    \n",
    "    # IHM->IHM\n",
    "    ihm_ihm_feats = augmentFeats(model, ihm_baseline_feats, \"ihm\")\n",
    "    axarr[2].axis('off')    # Pretty-up the resulting output by removing gridlines\n",
    "    axarr[2].imshow(np.transpose(ihm_ihm_feats), origin='lower', cmap=color_map, aspect='auto', interpolation='none')\n",
    "    axarr[2].set_title(\"IHM>IHM\")\n",
    "    \n",
    "    # IHM->SDM1\n",
    "    ihm_sdm1_feats = augmentFeats(model, ihm_baseline_feats, \"sdm1\")\n",
    "    axarr[3].axis('off')    # Pretty-up the resulting output by removing gridlines\n",
    "    axarr[3].imshow(np.transpose(ihm_sdm1_feats), origin='lower', cmap=color_map, aspect='auto', interpolation='none')\n",
    "    axarr[3].set_title(\"IHM>SDM1\")\n",
    "    \n",
    "    # IHM transform difference\n",
    "    ihm_transform_diff = ihm_sdm1_feats - ihm_ihm_feats\n",
    "    axarr[4].axis('off')    # Pretty-up the resulting output by removing gridlines\n",
    "    axarr[4].imshow(np.transpose(ihm_transform_diff), origin='lower', cmap=color_map, aspect='auto', interpolation='none')\n",
    "    axarr[4].set_title(\"IHM>SDM1 and IHM>IHM difference\")\n",
    "    \n",
    "    # SDM1->SDM1\n",
    "    sdm1_sdm1_feats = augmentFeats(model, sdm1_baseline_feats, \"sdm1\")\n",
    "    axarr[5].axis('off')    # Pretty-up the resulting output by removing gridlines\n",
    "    axarr[5].imshow(np.transpose(sdm1_sdm1_feats), origin='lower', cmap=color_map, aspect='auto', interpolation='none')\n",
    "    axarr[5].set_title(\"SDM1>SDM1\")\n",
    "    \n",
    "    # SDM1->IHM\n",
    "    sdm1_ihm_feats = augmentFeats(model, sdm1_baseline_feats, \"ihm\")\n",
    "    axarr[6].axis('off')    # Pretty-up the resulting output by removing gridlines\n",
    "    axarr[6].imshow(np.transpose(sdm1_ihm_feats), origin='lower', cmap=color_map, aspect='auto', interpolation='none')\n",
    "    axarr[6].set_title(\"SDM1>IHM\")\n",
    "    \n",
    "    # SDM1 transform difference\n",
    "    sdm1_transform_diff = sdm1_ihm_feats - sdm1_sdm1_feats\n",
    "    axarr[7].axis('off')    # Pretty-up the resulting output by removing gridlines\n",
    "    axarr[7].imshow(np.transpose(sdm1_transform_diff), origin='lower', cmap=color_map, aspect='auto', interpolation='none')\n",
    "    axarr[7].set_title(\"SDM1>IHM and SDM1>SDM1 difference\")\n",
    "    \n",
    "    # IHM backtranslated\n",
    "    ihm_backtrans_feats = augmentFeats(model, ihm_sdm1_feats, \"ihm\")\n",
    "    axarr[8].axis('off')    # Pretty-up the resulting output by removing gridlines\n",
    "    axarr[8].imshow(np.transpose(ihm_backtrans_feats), origin='lower', cmap=color_map, aspect='auto', interpolation='none')\n",
    "    axarr[8].set_title(\"IHM backtranslated\")\n",
    "    \n",
    "    # SDM1 backtranslated\n",
    "    sdm1_backtrans_feats = augmentFeats(model, sdm1_ihm_feats, \"sdm1\")\n",
    "    axarr[9].axis('off')    # Pretty-up the resulting output by removing gridlines\n",
    "    axarr[9].imshow(np.transpose(sdm1_backtrans_feats), origin='lower', cmap=color_map, aspect='auto', interpolation='none')\n",
    "    axarr[9].set_title(\"SDM1 backtranslated\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # fig.savefig(\"%s_idx%d.eps\" % (ihm_baseline_utt_id, utt_id_idx))\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# 43, 251 are good utterances (long + variations between IHM and SDM1)\n",
    "interact(plotParallelUtts, utt_id_idx=range(len(ihm_baseline)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af053562356441bea2b4fa484b82d281",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plotIHMToSDM1>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# color_map = \"coolwarm\"\n",
    "color_map = \"viridis\"\n",
    "def plotIHMToSDM1(utt_id_idx):\n",
    "    fig = plt.figure()\n",
    "    \n",
    "    fig.set_size_inches(8.5, 8.5)\n",
    "    ax = plt.gca()\n",
    "    \n",
    "    # IHM baseline feats\n",
    "    ihm_baseline_utt_id = ihm_baseline.utt_ids[utt_id_idx]\n",
    "    ihm_baseline_feats = ihm_baseline.feats_for_uttid(ihm_baseline_utt_id)\n",
    "    \n",
    "    # IHM->SDM1\n",
    "    ihm_sdm1_feats = augmentFeats(model, ihm_baseline_feats, \"sdm1\")\n",
    "    ax.axis('off')    # Pretty-up the resulting output by removing gridlines\n",
    "    ax.imshow(np.transpose(ihm_sdm1_feats), origin='lower', cmap=color_map, aspect='auto', interpolation='none')\n",
    "    ax.set_title(\"IHM>SDM1\")\n",
    "    \n",
    "    # fig.savefig(\"%s_idx%d_IHMToSDM1.eps\" % (ihm_baseline_utt_id, utt_id_idx))\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# 43, 251 are good utterances (long + variations between IHM and SDM1)\n",
    "interact(plotIHMToSDM1, utt_id_idx=range(len(ihm_baseline)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def realOrFake(model, feats, decoder_class):\n",
    "    feats_numpy = feats.reshape((-1, freq_dim))\n",
    "    num_frames = feats_numpy.shape[0]\n",
    "    real_confidence = np.empty((1, num_frames))\n",
    "    for i in range(num_frames):\n",
    "        frame_spliced = np.zeros((time_dim, freq_dim))\n",
    "        frame_spliced[left_context - min(i, left_context):left_context, :] = feats_numpy[i - min(i, left_context):i, :]\n",
    "        frame_spliced[left_context, :] = feats_numpy[i, :]\n",
    "        frame_spliced[left_context + 1:left_context + 1 + min(num_frames - i - 1, right_context), :] = feats_numpy[i + 1:i + 1 + min(num_frames - i - 1, right_context), :]\n",
    "        frame_tensor = Variable(torch.FloatTensor(frame_spliced))\n",
    "\n",
    "        confidence = model.forward_gan(frame_tensor, decoder_class)\n",
    "        confidence_numpy = confidence.cpu().data.numpy().reshape((-1))[0]\n",
    "        real_confidence[0, i] = confidence_numpy\n",
    "    return real_confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classifications(confidences):\n",
    "    classifications_bool = (confidences >= 0.5)\n",
    "    return classifications_bool.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96477c5afefe4304beedceeb81675788",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plotRealOrFake>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yesNoColorMap = \"RdYlGn\"\n",
    "def plotRealOrFake(utt_id_idx):\n",
    "    fig, axarr = plt.subplots(6, sharex=True)\n",
    "    \n",
    "    fig.set_size_inches(8.5, 11)\n",
    "    \n",
    "    # IHM baseline\n",
    "    ihm_baseline_utt_id = ihm_baseline.utt_ids[utt_id_idx]\n",
    "    ihm_baseline_feats = ihm_baseline.feats_for_uttid(ihm_baseline_utt_id)\n",
    "    axarr[0].axis('off')    # Pretty-up the resulting output by removing gridlines\n",
    "    axarr[0].imshow(classifications(realOrFake(model, ihm_baseline_feats, \"ihm\")), origin='lower', cmap=yesNoColorMap, aspect='auto', interpolation='none', vmin=0.0, vmax=1.0)\n",
    "    axarr[0].set_title(\"IHM\")\n",
    "    \n",
    "    # SDM1 baseline\n",
    "    sdm1_baseline_utt_id = sdm1_baseline.utt_ids[utt_id_idx]\n",
    "    sdm1_baseline_feats = sdm1_baseline.feats_for_uttid(sdm1_baseline_utt_id)\n",
    "    axarr[1].axis('off')    # Pretty-up the resulting output by removing gridlines\n",
    "    axarr[1].imshow(classifications(realOrFake(model, sdm1_baseline_feats, \"sdm1\")), origin='lower', cmap=yesNoColorMap, aspect='auto', interpolation='none', vmin=0.0, vmax=1.0)\n",
    "    axarr[1].set_title(\"SDM1\")\n",
    "    \n",
    "    # IHM->IHM\n",
    "    ihm_ihm_feats = augmentFeats(model, ihm_baseline_feats, \"ihm\")\n",
    "    axarr[2].axis('off')    # Pretty-up the resulting output by removing gridlines\n",
    "    axarr[2].imshow(classifications(realOrFake(model, ihm_ihm_feats, \"ihm\")), origin='lower', cmap=yesNoColorMap, aspect='auto', interpolation='none', vmin=0.0, vmax=1.0)\n",
    "    axarr[2].set_title(\"IHM>IHM\")\n",
    "    \n",
    "    # IHM->SDM1\n",
    "    ihm_sdm1_feats = augmentFeats(model, ihm_baseline_feats, \"sdm1\")\n",
    "    axarr[3].axis('off')    # Pretty-up the resulting output by removing gridlines\n",
    "    axarr[3].imshow(classifications(realOrFake(model, ihm_sdm1_feats, \"sdm1\")), origin='lower', cmap=yesNoColorMap, aspect='auto', interpolation='none', vmin=0.0, vmax=1.0)\n",
    "    axarr[3].set_title(\"IHM>SDM1\")\n",
    "    \n",
    "    # SDM1->SDM1\n",
    "    sdm1_sdm1_feats = augmentFeats(model, sdm1_baseline_feats, \"sdm1\")\n",
    "    axarr[4].axis('off')    # Pretty-up the resulting output by removing gridlines\n",
    "    axarr[4].imshow(classifications(realOrFake(model, sdm1_sdm1_feats, \"sdm1\")), origin='lower', cmap=yesNoColorMap, aspect='auto', interpolation='none', vmin=0.0, vmax=1.0)\n",
    "    axarr[4].set_title(\"SDM1>SDM1\")\n",
    "    \n",
    "    # SDM1->IHM\n",
    "    sdm1_ihm_feats = augmentFeats(model, sdm1_baseline_feats, \"ihm\")\n",
    "    axarr[5].axis('off')    # Pretty-up the resulting output by removing gridlines\n",
    "    axarr[5].imshow(classifications(realOrFake(model, sdm1_ihm_feats, \"ihm\")), origin='lower', cmap=yesNoColorMap, aspect='auto', interpolation='none', vmin=0.0, vmax=1.0)\n",
    "    axarr[5].set_title(\"SDM1>IHM\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 43, 251 are good utterances (long + variations between IHM and SDM1)\n",
    "interact(plotRealOrFake, utt_id_idx=range(len(ihm_baseline)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IF DATA AUGMENTATION ALREADY RAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set up augmented dev datasets\n"
     ]
    }
   ],
   "source": [
    "# Set up augmented datasets for IHM->IHM, IHM->SDM1, SDM1->SDM1, SDM1->IHM (dev set only)\n",
    "model_type = \"ae\"\n",
    "adversarial = True\n",
    "gan=False\n",
    "augmented_data_base_dir = \"/data/sls/scratch/atitus5/meng/augmented_data/cnn/%s/%s\" % (dataset,\n",
    "                                                                                       expt_name)\n",
    "\n",
    "if adversarial:\n",
    "    augmented_data_dir = \"%s/adversarial_fc_%s_act_%s_%s_ratio%s\" % (augmented_data_base_dir,\n",
    "                                                                     adv_fc_delim,\n",
    "                                                                     adv_activation,\n",
    "                                                                     model_type,\n",
    "                                                                     str(noise_ratio))\n",
    "elif gan:\n",
    "    augmented_data_dir = \"%s/gan_fc_%s_act_%s_%s_ratio%s\" % (augmented_data_base_dir,\n",
    "                                                                     gan_fc_delim,\n",
    "                                                                     gan_activation,\n",
    "                                                                     model_type,\n",
    "                                                                     str(noise_ratio))\n",
    "else:\n",
    "    augmented_data_dir = \"%s/%s_ratio%s\" % (augmented_data_base_dir,\n",
    "                                            model_type,\n",
    "                                            str(noise_ratio))\n",
    "\n",
    "ihm_ihm = HaoEvalDataset(os.path.join(augmented_data_dir, \"dev-src_ihm-tar_ihm.scp\"))\n",
    "ihm_sdm1 = HaoEvalDataset(os.path.join(augmented_data_dir, \"dev-src_ihm-tar_sdm1.scp\"))\n",
    "sdm1_sdm1 = HaoEvalDataset(os.path.join(augmented_data_dir, \"dev-src_sdm1-tar_sdm1.scp\"))\n",
    "sdm1_ihm = HaoEvalDataset(os.path.join(augmented_data_dir, \"dev-src_sdm1-tar_ihm.scp\"))\n",
    "print(\"Set up augmented dev datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f34c2227fab4090bc0723988107caa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plotParallelUtts>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# color_map = \"coolwarm\"\n",
    "color_map = \"viridis\"\n",
    "def plotParallelUtts(utt_id_idx):\n",
    "    fig, axarr = plt.subplots(6, sharex=True)\n",
    "    \n",
    "    fig.set_size_inches(8.5, 11)\n",
    "    \n",
    "    # IHM baseline\n",
    "    ihm_baseline_utt_id = ihm_baseline.utt_ids[utt_id_idx]\n",
    "    ihm_baseline_feats = np.transpose(ihm_baseline.feats_for_uttid(ihm_baseline_utt_id))\n",
    "    axarr[0].axis('off')    # Pretty-up the resulting output by removing gridlines\n",
    "    axarr[0].imshow(ihm_baseline_feats, origin='lower', cmap=color_map, aspect='auto', interpolation='none')\n",
    "    axarr[0].set_title(\"IHM\")\n",
    "    \n",
    "    # SDM1 baseline\n",
    "    sdm1_baseline_utt_id = sdm1_baseline.utt_ids[utt_id_idx]\n",
    "    sdm1_baseline_feats = np.transpose(sdm1_baseline.feats_for_uttid(sdm1_baseline_utt_id))\n",
    "    axarr[1].axis('off')    # Pretty-up the resulting output by removing gridlines\n",
    "    axarr[1].imshow(sdm1_baseline_feats, origin='lower', cmap=color_map, aspect='auto', interpolation='none')\n",
    "    axarr[1].set_title(\"SDM1\")\n",
    "    \n",
    "    # IHM->IHM baseline\n",
    "    ihm_ihm_utt_id = ihm_ihm.utt_ids[utt_id_idx]\n",
    "    ihm_ihm_feats = np.transpose(ihm_ihm.feats_for_uttid(ihm_ihm_utt_id))\n",
    "    axarr[2].axis('off')    # Pretty-up the resulting output by removing gridlines\n",
    "    axarr[2].imshow(ihm_ihm_feats, origin='lower', cmap=color_map, aspect='auto', interpolation='none')\n",
    "    axarr[2].set_title(\"IHM>IHM\")\n",
    "    \n",
    "    # IHM->SDM1 baseline\n",
    "    ihm_sdm1_utt_id = ihm_sdm1.utt_ids[utt_id_idx]\n",
    "    ihm_sdm1_feats = np.transpose(ihm_sdm1.feats_for_uttid(ihm_sdm1_utt_id))\n",
    "    axarr[3].axis('off')    # Pretty-up the resulting output by removing gridlines\n",
    "    axarr[3].imshow(ihm_sdm1_feats, origin='lower', cmap=color_map, aspect='auto', interpolation='none')\n",
    "    axarr[3].set_title(\"IHM>SDM1\")\n",
    "    \n",
    "    # SDM1->SDM1 baseline\n",
    "    sdm1_sdm1_utt_id = sdm1_sdm1.utt_ids[utt_id_idx]\n",
    "    sdm1_sdm1_feats = np.transpose(sdm1_sdm1.feats_for_uttid(sdm1_sdm1_utt_id))\n",
    "    axarr[4].axis('off')    # Pretty-up the resulting output by removing gridlines\n",
    "    axarr[4].imshow(sdm1_sdm1_feats, origin='lower', cmap=color_map, aspect='auto', interpolation='none')\n",
    "    axarr[4].set_title(\"SDM1>SDM1\")\n",
    "    \n",
    "    # SDM1->IHM baseline\n",
    "    sdm1_ihm_utt_id = sdm1_ihm.utt_ids[utt_id_idx]\n",
    "    sdm1_ihm_feats = np.transpose(sdm1_ihm.feats_for_uttid(sdm1_ihm_utt_id))\n",
    "    axarr[5].axis('off')    # Pretty-up the resulting output by removing gridlines\n",
    "    axarr[5].imshow(sdm1_ihm_feats, origin='lower', cmap=color_map, aspect='auto', interpolation='none')\n",
    "    axarr[5].set_title(\"SDM1>IHM\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # fig.savefig(\"%s_idx%d.eps\" % (ihm_baseline_utt_id, utt_id_idx))\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# 43, 251 are good utterances (long + variations between IHM and SDM1)\n",
    "interact(plotParallelUtts, utt_id_idx=range(len(ihm_baseline)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
