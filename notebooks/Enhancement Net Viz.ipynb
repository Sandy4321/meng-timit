{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../models\")\n",
    "sys.path.append(\"../py_utils\")\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from ipywidgets import interact, fixed\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from models import EnhancementNet\n",
    "from kaldi_data import KaldiEvalDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using experiment C_64_128_128_K_5_3_3_P_2_0_2_LATENT_512_PHONE_FC__512_512/BN_false_OPT_Adam_LR_0.0001_EPOCHS_35_BATCH_256\n"
     ]
    }
   ],
   "source": [
    "# First, the env variables needed from path.sh\n",
    "os.environ[\"LOGS\"] = \"/data/sls/scratch/atitus5/meng/logs\"\n",
    "os.environ[\"MODELS\"] = \"/data/sls/scratch/atitus5/meng/models\"\n",
    "os.environ[\"FEATS\"] = \"/data/sls/scratch/atitus5/meng/feats\"\n",
    "\n",
    "# Now, from models/base_config.sh\n",
    "os.environ[\"FEAT_DIM\"]=\"80\"      # 80-dim Mel filter bank\n",
    "os.environ[\"LEFT_CONTEXT\"]=\"7\"\n",
    "os.environ[\"RIGHT_CONTEXT\"]=\"7\"\n",
    "os.environ[\"OPTIMIZER\"]=\"Adam\"\n",
    "os.environ[\"LEARNING_RATE\"]=\"0.0001\"\n",
    "os.environ[\"EPOCHS\"]=\"35\"\n",
    "os.environ[\"BATCH_SIZE\"]=\"256\"\n",
    "\n",
    "channels=[64,128,128]\n",
    "kernels=[5,3,3]\n",
    "downsamples=[2,0,2]\n",
    "os.environ[\"CHANNELS_DELIM\"]=\"_%s\" % (\"_\".join(map(str, channels)))\n",
    "os.environ[\"KERNELS_DELIM\"]=\"_%s\" % (\"_\".join(map(str, kernels)))\n",
    "os.environ[\"DOWNSAMPLES_DELIM\"]=\"_%s\" % (\"_\".join(map(str, downsamples)))\n",
    "\n",
    "latent_dim=512\n",
    "os.environ[\"LATENT_DIM\"]=str(latent_dim)\n",
    "\n",
    "os.environ[\"USE_BATCH_NORM\"]=\"false\"\n",
    "\n",
    "phones_fc=[512,512]\n",
    "os.environ[\"PHONE_FC_DELIM\"]=\"_%s\" % (\"_\".join(map(str, phones_fc)))\n",
    "os.environ[\"NUM_PHONES\"]=\"2020\"\n",
    "\n",
    "clean_dataset = \"timit_clean\"\n",
    "dirty_dataset = \"timit_dirty_600_rir\"\n",
    "\n",
    "os.environ[\"CLEAN_DATASET\"]=clean_dataset\n",
    "os.environ[\"CLEAN_FEATS\"]=\"%s/%s\" % (os.environ[\"FEATS\"], os.environ[\"CLEAN_DATASET\"])\n",
    "\n",
    "os.environ[\"DIRTY_DATASET\"]=dirty_dataset\n",
    "os.environ[\"DIRTY_FEATS\"]=\"%s/%s\" % (os.environ[\"FEATS\"], os.environ[\"DIRTY_DATASET\"])\n",
    "\n",
    "os.environ[\"EXPT_NAME\"]=\"C%s_K%s_P%s_LATENT_%s_PHONE_FC_%s/BN_%s_OPT_%s_LR_%s_EPOCHS_%s_BATCH_%s\" % (os.environ[\"CHANNELS_DELIM\"],\n",
    "                                                                                                     os.environ[\"KERNELS_DELIM\"],\n",
    "                                                                                                     os.environ[\"DOWNSAMPLES_DELIM\"],\n",
    "                                                                                                     os.environ[\"LATENT_DIM\"],\n",
    "                                                                                                     os.environ[\"PHONE_FC_DELIM\"],\n",
    "                                                                                                     os.environ[\"USE_BATCH_NORM\"],\n",
    "                                                                                                     os.environ[\"OPTIMIZER\"],\n",
    "                                                                                                     os.environ[\"LEARNING_RATE\"],\n",
    "                                                                                                     os.environ[\"EPOCHS\"],\n",
    "                                                                                                     os.environ[\"BATCH_SIZE\"])\n",
    "\n",
    "os.environ[\"MODEL_DIR\"]=\"%s/%s/%s\" % (os.environ[\"MODELS\"], os.environ[\"DIRTY_DATASET\"], os.environ[\"EXPT_NAME\"])\n",
    "\n",
    "# Check that the environment variables worked\n",
    "print(\"Using experiment %s\" % os.environ[\"EXPT_NAME\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set up baseline test datasets\n"
     ]
    }
   ],
   "source": [
    "# Set up datasets for clean, dirty baselines (test set only)\n",
    "clean_feat_dir = \"%s/test\" % os.environ[\"CLEAN_FEATS\"]\n",
    "# clean_baseline = KaldiEvalDataset(os.path.join(clean_feat_dir, \"feats.scp\"))\n",
    "clean_baseline = KaldiEvalDataset(os.path.join(clean_feat_dir, \"feats-norm.scp\"))\n",
    "\n",
    "dirty_feat_dir = \"%s/test\" % os.environ[\"DIRTY_FEATS\"]\n",
    "# dirty_baseline = KaldiEvalDataset(os.path.join(dirty_feat_dir, \"feats.scp\"))\n",
    "dirty_baseline = KaldiEvalDataset(os.path.join(dirty_feat_dir, \"feats-norm.scp\"))\n",
    "\n",
    "print(\"Set up baseline test datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EnhancementNet(\n",
       "  (encoder): Encoder(\n",
       "    (encoder): Sequential(\n",
       "      (conv2d_0): Conv2d (1, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "      (ReLU_0): ReLU()\n",
       "      (maxpool2d_0): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), dilation=(1, 1))\n",
       "      (conv2d_1): Conv2d (64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (ReLU_1): ReLU()\n",
       "      (conv2d_2): Conv2d (128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (ReLU_2): ReLU()\n",
       "      (maxpool2d_2): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), dilation=(1, 1))\n",
       "    )\n",
       "    (latent): Sequential(\n",
       "      (lin_final): Linear(in_features=15232, out_features=512)\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (latent): Sequential(\n",
       "      (ReLU_final): ReLU()\n",
       "      (lin_final): Linear(in_features=512, out_features=15232)\n",
       "    )\n",
       "    (decoder): Sequential(\n",
       "      (ReLU_2): ReLU()\n",
       "      (maxunpool2d_2): MaxUnpool2d(kernel_size=(1, 2), stride=(1, 2), padding=(0, 0))\n",
       "      (conv2d_2): Conv2d (128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
       "      (ReLU_1): ReLU()\n",
       "      (conv2d_1): Conv2d (128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
       "      (ReLU_0): ReLU()\n",
       "      (maxunpool2d_0): MaxUnpool2d(kernel_size=(1, 2), stride=(1, 2), padding=(0, 0))\n",
       "      (conv2d_0): Conv2d (64, 1, kernel_size=(5, 5), stride=(1, 1), padding=(4, 4))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = EnhancementNet()\n",
    "checkpoint = torch.load(model.ckpt_path(), map_location=lambda storage,loc: storage)\n",
    "model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "freq_dim = int(os.environ[\"FEAT_DIM\"])\n",
    "left_context = int(os.environ[\"LEFT_CONTEXT\"])\n",
    "right_context = int(os.environ[\"RIGHT_CONTEXT\"])\n",
    "time_dim = (left_context + right_context + 1)\n",
    "def augmentFeats(model, feats):\n",
    "    feats_numpy = feats.reshape((-1, freq_dim))\n",
    "    num_frames = feats_numpy.shape[0]\n",
    "    decoded_feats = np.empty((num_frames, freq_dim))\n",
    "    for i in range(num_frames):\n",
    "        frame_spliced = np.zeros((time_dim, freq_dim))\n",
    "        frame_spliced[left_context - min(i, left_context):left_context, :] = feats_numpy[i - min(i, left_context):i, :]\n",
    "        frame_spliced[left_context, :] = feats_numpy[i, :]\n",
    "        frame_spliced[left_context + 1:left_context + 1 + min(num_frames - i - 1, right_context), :] = feats_numpy[i + 1:i + 1 + min(num_frames - i - 1, right_context), :]\n",
    "        frame_tensor = Variable(torch.FloatTensor(frame_spliced))\n",
    "\n",
    "        recon_frames = model.forward(frame_tensor)\n",
    "        recon_frames_numpy = recon_frames.cpu().data.numpy().reshape((-1, freq_dim))\n",
    "        decoded_feats[i, :] = recon_frames_numpy[left_context:left_context + 1, :]\n",
    "    return decoded_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f04dc84526b43898c7a008827e90b3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plotParallelUtts>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# color_map = \"coolwarm\"\n",
    "color_map = \"viridis\"\n",
    "min_val = -3.0\n",
    "max_val = 3.0\n",
    "\n",
    "def plotParallelUtts(utt_id_idx):\n",
    "    fig, axarr = plt.subplots(2, 2, sharex=True)\n",
    "    \n",
    "    fig.set_size_inches(12, 6)\n",
    "    \n",
    "    # CLEAN baseline\n",
    "    clean_baseline_utt_id = clean_baseline.utt_ids[utt_id_idx]\n",
    "    clean_baseline_feats = clean_baseline.feats_for_uttid(clean_baseline_utt_id)\n",
    "    axarr[0, 0].axis('off')    # Pretty-up the resulting output by removing gridlines\n",
    "    axarr[0, 0].imshow(np.transpose(clean_baseline_feats), vmin=min_val, vmax=max_val, origin='lower', cmap=color_map, aspect='auto', interpolation='none')\n",
    "    axarr[0, 0].set_title(\"CLEAN\")\n",
    "    \n",
    "    # DIRTY baseline\n",
    "    dirty_baseline_utt_id = dirty_baseline.utt_ids[utt_id_idx]\n",
    "    dirty_baseline_feats = dirty_baseline.feats_for_uttid(dirty_baseline_utt_id)\n",
    "    axarr[0, 1].axis('off')    # Pretty-up the resulting output by removing gridlines\n",
    "    axarr[0, 1].imshow(np.transpose(dirty_baseline_feats), vmin=min_val, vmax=max_val, origin='lower', cmap=color_map, aspect='auto', interpolation='none')\n",
    "    axarr[0, 1].set_title(\"DIRTY\")\n",
    "    \n",
    "    \n",
    "    # CLEAN->CLEAN\n",
    "    clean_clean_feats = augmentFeats(model, clean_baseline_feats)\n",
    "    axarr[1, 0].axis('off')    # Pretty-up the resulting output by removing gridlines\n",
    "    axarr[1, 0].imshow(np.transpose(clean_clean_feats), vmin=min_val, vmax=max_val, origin='lower', cmap=color_map, aspect='auto', interpolation='none')\n",
    "    axarr[1, 0].set_title(\"CLEAN>CLEAN\")\n",
    "\n",
    "    # DIRTY->CLEAN\n",
    "    dirty_clean_feats = augmentFeats(model, dirty_baseline_feats)\n",
    "    axarr[1, 1].axis('off')    # Pretty-up the resulting output by removing gridlines\n",
    "    axarr[1, 1].imshow(np.transpose(dirty_clean_feats), vmin=min_val, vmax=max_val, origin='lower', cmap=color_map, aspect='auto', interpolation='none')\n",
    "    axarr[1, 1].set_title(\"DIRTY>CLEAN\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    fig.savefig(\"%s_idx%d.eps\" % (clean_baseline_utt_id, utt_id_idx))\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "interact(plotParallelUtts, utt_id_idx=range(len(clean_baseline)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
