{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../cnn\")\n",
    "sys.path.append(\"../utils\")\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from ipywidgets import interact, fixed\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# import seaborn as sns; sns.set()\n",
    "\n",
    "from cnn_md import CNNEnd2EndMultidecoder\n",
    "from kaldi_data import KaldiEvalDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using experiment LOSS_MSELoss/RECON_false_TRANS_false_ENC_C_32_32_K_3_3_P_2_2_F_256/LATENT_256/DEC_F_256_C_32_32_K_3_3_P_2_2/ACT_ReLU_BN_false_WEIGHT_INIT_xavier_uniform/OPT_Adam_LR_0.001_L2_REG_0.0_EPOCHS_100_BATCH_64\n"
     ]
    }
   ],
   "source": [
    "# Set up environment variables for the model we want to examine\n",
    "# NOT necessarily the current environment variables!!\n",
    "\n",
    "feat_dim=40\n",
    "left_context=5\n",
    "right_context=5\n",
    "\n",
    "optimizer=\"Adam\"\n",
    "learning_rate=\"0.001\" # Use string instead of float to prevent Python's auto-formatting...\n",
    "l2_reg=\"0.0\" # Use string instead of float to prevent Python's auto-formatting...\n",
    "epochs=100\n",
    "batch_size=64\n",
    "\n",
    "enc_channels=[32,32]\n",
    "enc_kernels=[3,3]\n",
    "enc_downsamples=[2,2]\n",
    "enc_fc=[256]\n",
    "\n",
    "latent_dim=256\n",
    "\n",
    "dec_fc=[256]\n",
    "dec_channels=[32,32]\n",
    "dec_kernels=[3,3]\n",
    "dec_upsamples=[2,2]\n",
    "\n",
    "decoder_classes=[\"clean\", \"dirty\"]\n",
    "\n",
    "use_batch_norm=False\n",
    "use_batch_norm_str = \"true\" if use_batch_norm else \"false\"\n",
    "activation=\"ReLU\"\n",
    "weight_init=\"xavier_uniform\"\n",
    "\n",
    "enc_channels_delim=\"_\" + \"_\".join(map(str, enc_channels))\n",
    "if len(enc_channels) == 0:\n",
    "     # need to recreate bash join behavior with empty array\n",
    "    enc_channels_delim=\"_\"\n",
    "enc_kernels_delim=\"_\" + \"_\".join(map(str, enc_kernels))\n",
    "if len(enc_kernels) == 0:\n",
    "     # need to recreate bash join behavior with empty array\n",
    "    enc_kernels_delim=\"_\"\n",
    "enc_downsamples_delim=\"_\" + \"_\".join(map(str, enc_downsamples))\n",
    "if len(enc_downsamples) == 0:\n",
    "     # need to recreate bash join behavior with empty array\n",
    "    enc_downsamples_delim=\"_\"\n",
    "enc_fc_delim=\"_\" + \"_\".join(map(str, enc_fc))\n",
    "if len(enc_fc) == 0:\n",
    "     # need to recreate bash join behavior with empty array\n",
    "    enc_fc_delim=\"_\"\n",
    "    \n",
    "dec_fc_delim=\"_\" + \"_\".join(map(str, dec_fc))\n",
    "if len(dec_fc) == 0:\n",
    "     # need to recreate bash join behavior with empty array\n",
    "    dec_fc_delim=\"_\"\n",
    "dec_channels_delim=\"_\" + \"_\".join(map(str, dec_channels))\n",
    "if len(dec_channels) == 0:\n",
    "     # need to recreate bash join behavior with empty array\n",
    "    dec_channels_delim=\"_\"\n",
    "dec_kernels_delim=\"_\" + \"_\".join(map(str, dec_kernels))\n",
    "if len(dec_kernels) == 0:\n",
    "     # need to recreate bash join behavior with empty array\n",
    "    dec_kernels_delim=\"_\"\n",
    "dec_upsamples_delim=\"_\" + \"_\".join(map(str, dec_upsamples))\n",
    "if len(dec_upsamples) == 0:\n",
    "     # need to recreate bash join behavior with empty array\n",
    "    dec_upsamples_delim=\"_\"\n",
    "\n",
    "use_reconstruction = False\n",
    "use_reconstruction_str = \"true\" if use_reconstruction else \"false\"\n",
    "    \n",
    "use_transformation = False\n",
    "use_transformation_str = \"true\" if use_transformation else \"false\"\n",
    "\n",
    "# loss_func = \"L1Loss\"\n",
    "loss_func = \"MSELoss\"\n",
    "\n",
    "expt_name = \"LOSS_%s/RECON_%s_TRANS_%s_ENC_C%s_K%s_P%s_F%s/LATENT_%d/DEC_F%s_C%s_K%s_P%s/ACT_%s_BN_%s_WEIGHT_INIT_%s/OPT_%s_LR_%s_L2_REG_%s_EPOCHS_%d_BATCH_%d\" % (loss_func,\n",
    "                                                                                                                                        use_reconstruction_str,\n",
    "                                                                                                                                        use_transformation_str,\n",
    "                                                                                                                                        enc_channels_delim,\n",
    "                                                                                                                                        enc_kernels_delim, \n",
    "                                                                                                                                        enc_downsamples_delim, \n",
    "                                                                                                                                        enc_fc_delim,\n",
    "                                                                                                                                        latent_dim,\n",
    "                                                                                                                                        dec_fc_delim,\n",
    "                                                                                                                                        dec_channels_delim,\n",
    "                                                                                                                                        dec_kernels_delim,                                                                                                                   \n",
    "                                                                                                                                        dec_upsamples_delim,\n",
    "                                                                                                                                        activation,\n",
    "                                                                                                                                        use_batch_norm_str,\n",
    "                                                                                                                                        weight_init,\n",
    "                                                                                                                                        optimizer,\n",
    "                                                                                                                                        learning_rate,\n",
    "                                                                                                                                        l2_reg,\n",
    "                                                                                                                                        epochs,\n",
    "                                                                                                                                        batch_size)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "time_dim = (left_context + right_context + 1)\n",
    "freq_dim = feat_dim\n",
    "\n",
    "print(\"Using experiment %s\" % expt_name)\n",
    "\n",
    "clean_dataset = \"timit_clean\"\n",
    "dirty_dataset = \"timit_dirty_100_rir\"\n",
    "# dirty_dataset = \"timit_dirty_single_rir\"\n",
    "# dirty_dataset = \"timit_gaussian_5.0\"\n",
    "\n",
    "e2e_fc = [256,256]\n",
    "e2e_fc_delim=\"_\" + \"_\".join(map(str, e2e_fc))\n",
    "if len(e2e_fc) == 0:\n",
    "     # need to recreate bash join behavior with empty array\n",
    "    e2e_fc_delim=\"_\"\n",
    "e2e_activation = \"ReLU\"\n",
    "num_phones = 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set up baseline test datasets\n"
     ]
    }
   ],
   "source": [
    "# Set up datasets for clean, dirty baselines (test set only)\n",
    "clean_feat_dir = \"/data/sls/scratch/atitus5/meng/feats/%s/test\" % clean_dataset\n",
    "# clean_baseline = KaldiEvalDataset(os.path.join(clean_feat_dir, \"feats.scp\"))\n",
    "clean_baseline = KaldiEvalDataset(os.path.join(clean_feat_dir, \"feats-norm.scp\"))\n",
    "\n",
    "dirty_feat_dir = \"/data/sls/scratch/atitus5/meng/feats/%s/test\" % dirty_dataset\n",
    "# dirty_baseline = KaldiEvalDataset(os.path.join(dirty_feat_dir, \"feats.scp\"))\n",
    "dirty_baseline = KaldiEvalDataset(os.path.join(dirty_feat_dir, \"feats-norm.scp\"))\n",
    "\n",
    "print(\"Set up baseline test datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IF DATA AUGMENTATION NOT RUN YET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNEnd2EndMultidecoder(\n",
       "  (encoder_conv): Sequential(\n",
       "    (conv2d_0): Conv2d (1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
       "    (ReLU_0): ReLU()\n",
       "    (maxpool2d_0): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), dilation=(1, 1))\n",
       "    (conv2d_1): Conv2d (32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
       "    (ReLU_1): ReLU()\n",
       "    (maxpool2d_1): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), dilation=(1, 1))\n",
       "  )\n",
       "  (encoder_fc): Sequential(\n",
       "    (lin_0): Linear(in_features=5280, out_features=256)\n",
       "    (ReLU_0): ReLU()\n",
       "    (lin_final): Linear(in_features=256, out_features=256)\n",
       "  )\n",
       "  (decoder_fc_clean): Sequential(\n",
       "    (ReLU_0): ReLU()\n",
       "    (lin_0): Linear(in_features=256, out_features=256)\n",
       "    (ReLU_final): ReLU()\n",
       "    (lin_final): Linear(in_features=256, out_features=5280)\n",
       "  )\n",
       "  (decoder_deconv_clean): Sequential(\n",
       "    (ReLU_0): ReLU()\n",
       "    (maxunpool2d_0): MaxUnpool2d(kernel_size=(1, 2), stride=(1, 2), padding=(0, 0))\n",
       "    (conv2d_0): Conv2d (32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (ReLU_1): ReLU()\n",
       "    (maxunpool2d_1): MaxUnpool2d(kernel_size=(1, 2), stride=(1, 2), padding=(0, 0))\n",
       "    (conv2d_1): Conv2d (32, 1, kernel_size=(3, 3), stride=(1, 1))\n",
       "  )\n",
       "  (phone_classifier): Sequential(\n",
       "    (lin_0): Linear(in_features=440, out_features=256)\n",
       "    (ReLU_0): ReLU()\n",
       "    (lin_1): Linear(in_features=256, out_features=256)\n",
       "    (ReLU_1): ReLU()\n",
       "    (lin_final): Linear(in_features=256, out_features=2020)\n",
       "    (LogSoftmax_final): LogSoftmax()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_dir = \"/data/sls/scratch/atitus5/meng/models/cnn/%s/%s\" % (dirty_dataset,\n",
    "                                                                      expt_name)\n",
    "checkpoint_dir = \"%s/END2END_FC_%s_ACT_%s\" % (checkpoint_dir, e2e_fc_delim, e2e_activation)\n",
    "\n",
    "# USE ONLY DECODER CLASS CLEAN\n",
    "checkpoint_file = \"%s/best_md_e2e.pth.tar\" % checkpoint_dir\n",
    "\n",
    "model = CNNEnd2EndMultidecoder(freq_dim=freq_dim,\n",
    "                        splicing=[left_context, right_context], \n",
    "                        enc_channel_sizes=enc_channels,\n",
    "                        enc_kernel_sizes=enc_kernels,\n",
    "                        enc_downsample_sizes=enc_downsamples,\n",
    "                        enc_fc_sizes=enc_fc,\n",
    "                        latent_dim=latent_dim,\n",
    "                        dec_fc_sizes=dec_fc,\n",
    "                        dec_channel_sizes=dec_channels,\n",
    "                        dec_kernel_sizes=dec_kernels,\n",
    "                        dec_upsample_sizes=dec_upsamples,\n",
    "                        activation=activation,\n",
    "                        decoder_classes=[\"clean\"],\n",
    "                        use_batch_norm=use_batch_norm,\n",
    "                        weight_init=weight_init,\n",
    "                        e2e_fc_sizes=e2e_fc,\n",
    "                        e2e_activation=e2e_activation,\n",
    "                        num_phones=num_phones)\n",
    "\n",
    "        \n",
    "checkpoint = torch.load(checkpoint_file, map_location=lambda storage,loc: storage)\n",
    "model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def augmentFeats(model, feats):\n",
    "    # Only decoder through clean decoder\n",
    "    feats_numpy = feats.reshape((-1, freq_dim))\n",
    "    num_frames = feats_numpy.shape[0]\n",
    "    decoded_feats = np.empty((num_frames, freq_dim))\n",
    "    for i in range(num_frames):\n",
    "        frame_spliced = np.zeros((time_dim, freq_dim))\n",
    "        frame_spliced[left_context - min(i, left_context):left_context, :] = feats_numpy[i - min(i, left_context):i, :]\n",
    "        frame_spliced[left_context, :] = feats_numpy[i, :]\n",
    "        frame_spliced[left_context + 1:left_context + 1 + min(num_frames - i - 1, right_context), :] = feats_numpy[i + 1:i + 1 + min(num_frames - i - 1, right_context), :]\n",
    "        frame_tensor = Variable(torch.FloatTensor(frame_spliced))\n",
    "\n",
    "        recon_frames = model.forward_decoder(frame_tensor, \"clean\")\n",
    "        recon_frames_numpy = recon_frames.cpu().data.numpy().reshape((-1, freq_dim))\n",
    "        decoded_feats[i, :] = recon_frames_numpy[left_context:left_context + 1, :]\n",
    "    return decoded_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8791af089210431d8094aa9e6b8609ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plotParallelUtts>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# color_map = \"coolwarm\"\n",
    "color_map = \"viridis\"\n",
    "def plotParallelUtts(utt_id_idx):\n",
    "    fig, axarr = plt.subplots(3, 2, sharex=True)\n",
    "    \n",
    "    fig.set_size_inches(12, 8)\n",
    "    \n",
    "    # CLEAN baseline\n",
    "    clean_baseline_utt_id = clean_baseline.utt_ids[utt_id_idx]\n",
    "    clean_baseline_feats = clean_baseline.feats_for_uttid(clean_baseline_utt_id)\n",
    "    axarr[0, 0].axis('off')    # Pretty-up the resulting output by removing gridlines\n",
    "    axarr[0, 0].imshow(np.transpose(clean_baseline_feats), origin='lower', cmap=color_map, aspect='auto', interpolation='none')\n",
    "    axarr[0, 0].set_title(\"CLEAN\")\n",
    "    \n",
    "    # DIRTY baseline\n",
    "    dirty_baseline_utt_id = dirty_baseline.utt_ids[utt_id_idx]\n",
    "    dirty_baseline_feats = dirty_baseline.feats_for_uttid(dirty_baseline_utt_id)\n",
    "    axarr[0, 1].axis('off')    # Pretty-up the resulting output by removing gridlines\n",
    "    axarr[0, 1].imshow(np.transpose(dirty_baseline_feats), origin='lower', cmap=color_map, aspect='auto', interpolation='none')\n",
    "    axarr[0, 1].set_title(\"DIRTY\")\n",
    "    \n",
    "    \n",
    "    # CLEAN->CLEAN\n",
    "    clean_clean_feats = augmentFeats(model, clean_baseline_feats)\n",
    "    axarr[1, 0].axis('off')    # Pretty-up the resulting output by removing gridlines\n",
    "    axarr[1, 0].imshow(np.transpose(clean_clean_feats), origin='lower', cmap=color_map, aspect='auto', interpolation='none')\n",
    "    axarr[1, 0].set_title(\"CLEAN>CLEAN\")\n",
    "    \n",
    "    # CLEAN recon difference\n",
    "    clean_recon_diff = clean_clean_feats - clean_baseline_feats\n",
    "    axarr[2, 0].axis('off')    # Pretty-up the resulting output by removing gridlines\n",
    "    axarr[2, 0].imshow(np.transpose(clean_recon_diff), origin='lower', cmap=color_map, aspect='auto', interpolation='none')\n",
    "    axarr[2, 0].set_title(\"CLEAN>CLEAN and CLEAN baseline difference\")\n",
    "    \n",
    "    # DIRTY->CLEAN\n",
    "    dirty_clean_feats = augmentFeats(model, dirty_baseline_feats)\n",
    "    axarr[1, 1].axis('off')    # Pretty-up the resulting output by removing gridlines\n",
    "    axarr[1, 1].imshow(np.transpose(dirty_clean_feats), origin='lower', cmap=color_map, aspect='auto', interpolation='none')\n",
    "    axarr[1, 1].set_title(\"DIRTY>CLEAN\")\n",
    "    \n",
    "    # DIRTY transform difference\n",
    "    dirty_transform_diff = dirty_clean_feats - clean_baseline_feats\n",
    "    axarr[2, 1].axis('off')    # Pretty-up the resulting output by removing gridlines\n",
    "    axarr[2, 1].imshow(np.transpose(dirty_transform_diff), origin='lower', cmap=color_map, aspect='auto', interpolation='none')\n",
    "    axarr[2, 1].set_title(\"DIRTY>CLEAN and CLEAN baseline difference\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # fig.savefig(\"%s_idx%d.eps\" % (clean_baseline_utt_id, utt_id_idx))\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "interact(plotParallelUtts, utt_id_idx=range(len(clean_baseline)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
